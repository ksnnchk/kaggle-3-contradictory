{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from safetensors.torch import load_file\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "os.makedirs(\"/kaggle/working/best_model\", exist_ok=True)\n",
        "\n",
        "config = {\n",
        "    \"model_type\": \"deberta\",\n",
        "    \"architectures\": [\"CustomDeBERTa\"],\n",
        "    \"num_labels\": 3,\n",
        "    \"hidden_size\": 768,\n",
        "    \"intermediate_size\": 3072,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12\n",
        "}\n",
        "\n",
        "with open(\"/kaggle/working/best_model/config.json\", \"w\") as f:\n",
        "    json.dump(config, f)\n",
        "\n",
        "max_length = 256\n",
        "MODEL_NAME = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 1\n",
        "\n",
        "class CustomDeBERTa(nn.Module):\n",
        "    def __init__(self, model_name, num_labels):\n",
        "        super().__init__()\n",
        "        self.deberta = AutoModel.from_pretrained(model_name)\n",
        "        self.config = self.deberta.config  # Keep config\n",
        "        self.config.num_labels = num_labels  # Add number of classes\n",
        "\n",
        "        hidden_size = self.config.hidden_size\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, num_labels)\n",
        "        )\n",
        "\n",
        "        # Freeze layers\n",
        "        for param in self.deberta.parameters():\n",
        "            param.requires_grad = False\n",
        "        for layer in self.deberta.encoder.layer[-4:]:\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.classifier[-1].out_features),\n",
        "                          labels.view(-1))\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n",
        "\n",
        "    def save_pretrained(self, save_directory):\n",
        "        \"\"\"Custom method for saving model\"\"\"\n",
        "        os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "        # Save config\n",
        "        self.config.save_pretrained(save_directory)\n",
        "\n",
        "        # Save model weights\n",
        "        if hasattr(self, 'safe_serialization') and self.safe_serialization:\n",
        "            from safetensors.torch import save_file\n",
        "            save_file(self.state_dict(), os.path.join(save_directory, \"model.safetensors\"))\n",
        "        else:\n",
        "            torch.save(self.state_dict(), os.path.join(save_directory, \"pytorch_model.bin\"))\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length):\n",
        "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {'accuracy': accuracy_score(labels, predictions)}\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/train.csv\")\n",
        "    texts = (data['premise'] + \" [SEP] \" + data['hypothesis']).tolist()\n",
        "    labels = data['label'].values\n",
        "\n",
        "    # Tokenizer and datasets\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    dataset = TextDataset(texts, labels, tokenizer, max_length)\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
        "\n",
        "    # Model\n",
        "    model = CustomDeBERTa(MODEL_NAME, num_labels=3)\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./results\",\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        per_device_eval_batch_size=BATCH_SIZE,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_dir=\"./logs\",\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        greater_is_better=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    trainer.train()\n",
        "\n",
        "    # Save model\n",
        "    trainer.save_model(\"best_model\")\n",
        "    print(\"Model saved\")\n",
        "\n",
        "    output_dir = \"/kaggle/working/best_model\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save model (with save_pretrained method)\n",
        "    model.save_pretrained(output_dir)\n",
        "\n",
        "    # Save tokenizer\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "    print(f\"Model and tokenizer saved in {output_dir}\")\n",
        "    print(\"Directory contents:\")\n",
        "    print(os.listdir(output_dir))\n",
        "\n",
        "def evaluate_test_data():\n",
        "    # Load test data\n",
        "    test_data = pd.read_csv(\"/kaggle/input/contradictory-my-dear-watson/test.csv\")\n",
        "    test_texts = (test_data['premise'] + \" [SEP] \" + test_data['hypothesis']).tolist()\n",
        "    test_ids = test_data['id'].values\n",
        "\n",
        "    # Model path\n",
        "    model_path = \"/kaggle/working/best_model\"\n",
        "\n",
        "    # Check directory contents\n",
        "    print(\"Checking model files:\")\n",
        "    print(os.listdir(model_path))\n",
        "\n",
        "    # Check required files\n",
        "    required_files = ['config.json', 'model.safetensors', 'tokenizer_config.json']\n",
        "    for file in required_files:\n",
        "        if not os.path.exists(f\"{model_path}/{file}\"):\n",
        "            raise FileNotFoundError(f\"Required file not found: {file}\")\n",
        "\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Tokenizer loading error: {e}\")\n",
        "        print(\"Loading original tokenizer as fallback...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "        tokenizer.save_pretrained(model_path)  # Save for future use\n",
        "\n",
        "    # Load model\n",
        "    try:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_path,\n",
        "            trust_remote_code=True  # For custom models\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Model loading error: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Batch processing for memory efficiency\n",
        "    predictions = []\n",
        "    for i in range(0, len(test_texts), BATCH_SIZE):\n",
        "        batch_texts = test_texts[i:i+BATCH_SIZE]\n",
        "\n",
        "        # Tokenization with max length handling\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            truncation=True,\n",
        "            padding='longest',  # Auto-padding to longest sequence in batch\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        # Prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs[0]\n",
        "            batch_preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "            predictions.extend(batch_preds)\n",
        "\n",
        "    if len(predictions) != len(test_ids):\n",
        "        raise ValueError(f\"Predictions count ({len(predictions)}) doesn't match test examples ({len(test_ids)})\")\n",
        "\n",
        "    # Save results\n",
        "    submission_df = pd.DataFrame({\n",
        "        'id': test_ids,\n",
        "        'prediction': predictions\n",
        "    })\n",
        "\n",
        "    # Format validation\n",
        "    if not all(submission_df['prediction'].between(0, 2)):  # For 3 classes (0,1,2)\n",
        "        raise ValueError(\"Predictions must be in range 0-2\")\n",
        "\n",
        "    submission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
        "\n",
        "    # Additional validation\n",
        "    print(\"Checking saved files:\")\n",
        "    print(os.listdir(\"/kaggle/working/\"))\n",
        "\n",
        "    print(\"\\nFirst 5 rows of submission.csv:\")\n",
        "    print(submission_df.head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    evaluate_test_data()"
      ],
      "metadata": {
        "id": "pRSzwadomNdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}